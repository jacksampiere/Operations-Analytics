```{r warning=FALSE}
library(readr)
# read data
nba_stats = read.csv('nba-stats-2013-2019.csv')
```

Part 1: An initial linear regression model

```{r warning=FALSE}
# split into training and test set
train = nba_stats[nba_stats$Year < 2018,]
test = nba_stats[nba_stats$Year >= 2018,]
# run regression
lm_stats_1 = lm(PTS ~ . - Team - Year - G - Playoffs - PTS, data = train)
summary(lm_stats_1)
```

(a) The training set R2 is 1.

(b) The nonzero coefficients are those on X3P, X2P, and FT.

(c) The result of this regression is not surprising since all points must come from either 2-point FGs, 3-point FGs, or free throws. We are thus able to perfectly predict total points with these variables in the dataset.

Part 2: A better linear regression model

```{r}
lm_stats_2 = lm(PTS ~ X3PA + X2PA + FGA + FTA + ORB + DRB + AST + STL
                + BLK + TOV + PF, data=train)
summary(lm_stats_2)
```

(a) X3PA, X2PA, FTA, DRB, AST, and TOV are all statistically significant at the 0.05 level.

(b) The coefficient on X3PA implies that an increase in X3PA of 1 corresponds to an increase in PTS of 0.69129. This implies a probability of success of a 3-point attempt of 0.69129/3 = 0.23043.

(c) FGA does not have a coefficient in the model since it is perfectly collinear with X3PA, X2PA, and FTA since all field goal attempts must be one of those types.

```{r warning=FALSE}
# use regression to predict test set
pred = predict(lm_stats_2, newdata=test)
# compute SSE and SST
SSE = sum((test$PTS - pred)^2)
SST = sum((mean(train$PTS) - test$PTS)^2)
pred_r2 = 1 - SSE/SST
pred_r2
```

(d) The test set R2 is 0.9327728.

See Part 3 in Python.
